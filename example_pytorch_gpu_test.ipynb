{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0030b27",
   "metadata": {},
   "source": [
    "## 1. Install Jupyter and Dependencies\n",
    "\n",
    "Jupyter should already be installed. If not, run in the integrated terminal:\n",
    "\n",
    "```bash\n",
    ".venvcriptsython.exe -m pip install jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db561e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f436fead",
   "metadata": {},
   "source": [
    "## 2. Create a Jupyter Notebook File\n",
    "\n",
    "This file is already a Jupyter Notebook (`.ipynb`). You can create new ones using:\n",
    "- Command Palette: `Ctrl+Shift+P` → \"Jupyter: Create New Blank Notebook\"\n",
    "- Or manually save a `.ipynb` file in VS Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167f28d",
   "metadata": {},
   "source": [
    "## 3. Configure Python Kernel\n",
    "\n",
    "Make sure to select the correct kernel:\n",
    "1. Click \"Select Kernel\" in the top-right of the notebook\n",
    "2. Choose `.venv\\Scripts\\python.exe` (your local PyTorch environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13304e85",
   "metadata": {},
   "source": [
    "## 4. Install PyTorch\n",
    "\n",
    "PyTorch should already be installed in your `.venv` with CUDA support. If not, run:\n",
    "\n",
    "```bash\n",
    ".venvcriptsython.exe -m pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00784c",
   "metadata": {},
   "source": [
    "## 5. Write and Execute Basic Cells\n",
    "\n",
    "Below are example code cells. Execute each cell using **Shift+Enter** or the Run button."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7812df9",
   "metadata": {},
   "source": [
    "## 6. Import PyTorch and Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Device count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcbd4a9",
   "metadata": {},
   "source": [
    "### Create Tensors and Move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor on CPU\n",
    "x = torch.randn(1000, 1000)\n",
    "print(f\"Tensor on CPU - shape: {x.shape}, device: {x.device}\")\n",
    "\n",
    "# Move tensor to GPU\n",
    "if torch.cuda.is_available():\n",
    "    x_gpu = x.cuda()\n",
    "    print(f\"Tensor on GPU - shape: {x_gpu.shape}, device: {x_gpu.device}\")\n",
    "else:\n",
    "    print(\"CUDA not available, skipping GPU transfer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254db584",
   "metadata": {},
   "source": [
    "### Matrix Multiplication on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee73e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Create matrices on GPU\n",
    "    A = torch.randn(1000, 1000).cuda()\n",
    "    B = torch.randn(1000, 1000).cuda()\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    C = torch.matmul(A, B)\n",
    "    \n",
    "    print(f\"Matrix multiplication result:\")\n",
    "    print(f\"A shape: {A.shape}\")\n",
    "    print(f\"B shape: {B.shape}\")\n",
    "    print(f\"C shape: {C.shape}\")\n",
    "    print(f\"C device: {C.device}\")\n",
    "    print(f\"C mean value: {C.mean().item():.4f}\")\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef45ea",
   "metadata": {},
   "source": [
    "## 7. Run Notebook Cells - Performance Comparison: GPU vs CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test parameters\n",
    "size = 5000\n",
    "iterations = 5\n",
    "\n",
    "# Warm-up\n",
    "_ = torch.randn(100, 100)\n",
    "\n",
    "# CPU timing\n",
    "x_cpu = torch.randn(size, size)\n",
    "y_cpu = torch.randn(size, size)\n",
    "\n",
    "cpu_times = []\n",
    "for _ in range(iterations):\n",
    "    start = time.time()\n",
    "    result_cpu = torch.matmul(x_cpu, y_cpu)\n",
    "    cpu_times.append(time.time() - start)\n",
    "\n",
    "avg_cpu_time = sum(cpu_times) / len(cpu_times)\n",
    "print(f\"CPU Matrix Multiplication ({size}x{size}):\")\n",
    "print(f\"  Average time: {avg_cpu_time:.4f}s\")\n",
    "print(f\"  Times: {[f'{t:.4f}s' for t in cpu_times]}\")\n",
    "\n",
    "# GPU timing (if available)\n",
    "if torch.cuda.is_available():\n",
    "    x_gpu = torch.randn(size, size).cuda()\n",
    "    y_gpu = torch.randn(size, size).cuda()\n",
    "    \n",
    "    # Warm-up\n",
    "    _ = torch.randn(100, 100).cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    gpu_times = []\n",
    "    for _ in range(iterations):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        result_gpu = torch.matmul(x_gpu, y_gpu)\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_times.append(time.time() - start)\n",
    "    \n",
    "    avg_gpu_time = sum(gpu_times) / len(gpu_times)\n",
    "    print(f\"\\nGPU Matrix Multiplication ({size}x{size}):\")\n",
    "    print(f\"  Average time: {avg_gpu_time:.4f}s\")\n",
    "    print(f\"  Times: {[f'{t:.4f}s' for t in gpu_times]}\")\n",
    "    \n",
    "    speedup = avg_cpu_time / avg_gpu_time\n",
    "    print(f\"\\nSpeedup (CPU / GPU): {speedup:.2f}x\")\n",
    "else:\n",
    "    print(\"\\nGPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c5ce8",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "| Action | Shortcut |\n",
    "|--------|----------|\n",
    "| Run current cell | Shift+Enter |\n",
    "| Run all cells | Ctrl+Alt+Enter |\n",
    "| Insert cell below | Ctrl+Shift+A |\n",
    "| Delete cell | Ctrl+Shift+D |\n",
    "| Clear outputs | Right-click → Clear Outputs |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
